{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import os\n",
    "import geopandas as gpd\n",
    "from openeo_gfmap.backend import vito_connection, Backend, BackendContext\n",
    "from openeo_gfmap.fetching import FetchType\n",
    "from openeo_gfmap import TemporalContext, BoundingBoxExtent\n",
    "import json\n",
    "from openeo_gfmap.fetching.s2 import build_sentinel2_l2a_extractor\n",
    "from openeo_gfmap.preprocessing import mask_scl_dilation\n",
    "from openeo.processes import sort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TemporalContext('2018-01-01','2023-12-31')\n",
    "b_S2 = ['S2-B01','S2-B02','S2-B03','S2-B04','S2-B05','S2-B06','S2-B07','S2-B08','S2-B8A','S2-B11','S2-B12','S2-SCL']\n",
    "b_simple = [band.split('-')[-1] for band in b_S2]\n",
    "t_simple = ['2018-01-01','2023-12-31']\n",
    "def extract_and_save(b_S2,t,bbox,geom):\n",
    "    extraction_params = {\n",
    "        \"load_collection\":{\n",
    "            \"eo:cloud_cover\":lambda val: val <=20\n",
    "        }\n",
    "    }\n",
    "    s2_extractor = build_sentinel2_l2a_extractor(backend_context=BackendContext(Backend.TERRASCOPE),\n",
    "                                bands=b_S2,\n",
    "                                fetch_type=FetchType.TILE, \n",
    "                                **extraction_params)\n",
    "    s2_cube = s2_extractor.get_cube(vito_connection(),bbox,t) \n",
    "    \n",
    "    s2_masked = mask_scl_dilation(s2_cube)\n",
    "    s2_agg = s2_masked.aggregate_spatial(geom, reducer=\"mean\")\n",
    "\n",
    "    return s2_agg\n",
    "\n",
    "def extract_and_save_simple(b,t,bbox,geom):\n",
    "    conn = vito_connection()\n",
    "    s2_cube = conn.load_collection(\n",
    "        \"SENTINEL2_L2A\",\n",
    "        spatial_extent=bbox,\n",
    "        temporal_extent = t,\n",
    "        bands = b,\n",
    "        max_cloud_cover=10\n",
    "    )\n",
    "    s2_masked = s2_cube.process(\n",
    "        process_id = \"mask_scl_dilation\",\n",
    "        arguments = {\n",
    "            'data':s2_cube,\n",
    "            'scl_band_name':'SCL'\n",
    "        }\n",
    "    )\n",
    "    s2_agg = s2_masked.aggregate_spatial(geom, reducer=\"mean\")\n",
    "    return s2_agg\n",
    "\n",
    "def create_job(datacube, output_path):\n",
    "    job = datacube.create_job(\n",
    "        title=output_path.split('/')[-1].split('.')[0], out_format=\"CSV\"\n",
    "    )\n",
    "    job.start_and_wait()\n",
    "\n",
    "    for asset in job.get_results().get_assets():\n",
    "        if asset.metadata[\"type\"].startswith(\"text/csv\"):\n",
    "            asset.download(output_path)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShapefilePKZ1\n",
      "Authenticated using refresh token.\n",
      "0:00:00 Job 'j-240223ba5db547d183007c414a8bfb3f': send 'start'\n",
      "0:01:33 Job 'j-240223ba5db547d183007c414a8bfb3f': queued (progress N/A)\n",
      "0:01:38 Job 'j-240223ba5db547d183007c414a8bfb3f': queued (progress N/A)\n",
      "0:01:45 Job 'j-240223ba5db547d183007c414a8bfb3f': queued (progress N/A)\n",
      "0:01:53 Job 'j-240223ba5db547d183007c414a8bfb3f': queued (progress N/A)\n",
      "0:02:03 Job 'j-240223ba5db547d183007c414a8bfb3f': queued (progress N/A)\n",
      "0:02:16 Job 'j-240223ba5db547d183007c414a8bfb3f': queued (progress N/A)\n",
      "0:02:32 Job 'j-240223ba5db547d183007c414a8bfb3f': queued (progress N/A)\n",
      "0:02:51 Job 'j-240223ba5db547d183007c414a8bfb3f': queued (progress N/A)\n",
      "0:03:15 Job 'j-240223ba5db547d183007c414a8bfb3f': queued (progress N/A)\n",
      "0:03:45 Job 'j-240223ba5db547d183007c414a8bfb3f': queued (progress N/A)\n",
      "0:04:23 Job 'j-240223ba5db547d183007c414a8bfb3f': running (progress N/A)\n",
      "0:05:10 Job 'j-240223ba5db547d183007c414a8bfb3f': running (progress N/A)\n",
      "0:06:08 Job 'j-240223ba5db547d183007c414a8bfb3f': running (progress N/A)\n",
      "0:07:09 Job 'j-240223ba5db547d183007c414a8bfb3f': running (progress N/A)\n",
      "0:08:09 Job 'j-240223ba5db547d183007c414a8bfb3f': running (progress N/A)\n",
      "0:09:09 Job 'j-240223ba5db547d183007c414a8bfb3f': running (progress N/A)\n",
      "0:10:10 Job 'j-240223ba5db547d183007c414a8bfb3f': running (progress N/A)\n",
      "0:11:10 Job 'j-240223ba5db547d183007c414a8bfb3f': running (progress N/A)\n",
      "0:12:10 Job 'j-240223ba5db547d183007c414a8bfb3f': running (progress N/A)\n",
      "0:13:10 Job 'j-240223ba5db547d183007c414a8bfb3f': finished (progress N/A)\n",
      "finished 1/7\n",
      "ShapefilePPD1\n",
      "Authenticated using refresh token.\n",
      "0:00:00 Job 'j-240223137a29410ba8046fa033ef5e07': send 'start'\n",
      "0:00:23 Job 'j-240223137a29410ba8046fa033ef5e07': queued (progress N/A)\n",
      "0:00:29 Job 'j-240223137a29410ba8046fa033ef5e07': queued (progress N/A)\n",
      "0:00:35 Job 'j-240223137a29410ba8046fa033ef5e07': queued (progress N/A)\n",
      "0:00:43 Job 'j-240223137a29410ba8046fa033ef5e07': queued (progress N/A)\n",
      "0:00:53 Job 'j-240223137a29410ba8046fa033ef5e07': queued (progress N/A)\n",
      "0:01:06 Job 'j-240223137a29410ba8046fa033ef5e07': queued (progress N/A)\n",
      "0:01:21 Job 'j-240223137a29410ba8046fa033ef5e07': queued (progress N/A)\n",
      "0:01:41 Job 'j-240223137a29410ba8046fa033ef5e07': queued (progress N/A)\n",
      "0:02:05 Job 'j-240223137a29410ba8046fa033ef5e07': queued (progress N/A)\n",
      "0:02:35 Job 'j-240223137a29410ba8046fa033ef5e07': queued (progress N/A)\n",
      "0:03:13 Job 'j-240223137a29410ba8046fa033ef5e07': running (progress N/A)\n",
      "0:04:00 Job 'j-240223137a29410ba8046fa033ef5e07': running (progress N/A)\n",
      "0:04:59 Job 'j-240223137a29410ba8046fa033ef5e07': running (progress N/A)\n",
      "0:05:59 Job 'j-240223137a29410ba8046fa033ef5e07': running (progress N/A)\n",
      "0:06:59 Job 'j-240223137a29410ba8046fa033ef5e07': running (progress N/A)\n",
      "0:08:00 Job 'j-240223137a29410ba8046fa033ef5e07': running (progress N/A)\n",
      "0:09:02 Job 'j-240223137a29410ba8046fa033ef5e07': running (progress N/A)\n",
      "0:10:03 Job 'j-240223137a29410ba8046fa033ef5e07': running (progress N/A)\n",
      "0:11:03 Job 'j-240223137a29410ba8046fa033ef5e07': finished (progress N/A)\n",
      "finished 2/7\n",
      "ShapefilePPK1\n",
      "Authenticated using refresh token.\n",
      "0:00:00 Job 'j-24022397ddb34206bd8fa33268372626': send 'start'\n",
      "0:00:21 Job 'j-24022397ddb34206bd8fa33268372626': queued (progress N/A)\n",
      "0:00:26 Job 'j-24022397ddb34206bd8fa33268372626': queued (progress N/A)\n",
      "0:00:33 Job 'j-24022397ddb34206bd8fa33268372626': queued (progress N/A)\n",
      "0:00:41 Job 'j-24022397ddb34206bd8fa33268372626': queued (progress N/A)\n",
      "0:00:51 Job 'j-24022397ddb34206bd8fa33268372626': queued (progress N/A)\n",
      "0:01:04 Job 'j-24022397ddb34206bd8fa33268372626': queued (progress N/A)\n",
      "0:01:19 Job 'j-24022397ddb34206bd8fa33268372626': queued (progress N/A)\n",
      "0:01:39 Job 'j-24022397ddb34206bd8fa33268372626': queued (progress N/A)\n",
      "0:02:03 Job 'j-24022397ddb34206bd8fa33268372626': running (progress N/A)\n",
      "0:02:33 Job 'j-24022397ddb34206bd8fa33268372626': running (progress N/A)\n",
      "0:03:10 Job 'j-24022397ddb34206bd8fa33268372626': running (progress N/A)\n",
      "0:03:58 Job 'j-24022397ddb34206bd8fa33268372626': running (progress N/A)\n",
      "0:04:56 Job 'j-24022397ddb34206bd8fa33268372626': running (progress N/A)\n",
      "0:06:01 Job 'j-24022397ddb34206bd8fa33268372626': running (progress N/A)\n",
      "0:07:02 Job 'j-24022397ddb34206bd8fa33268372626': running (progress N/A)\n",
      "0:08:02 Job 'j-24022397ddb34206bd8fa33268372626': running (progress N/A)\n",
      "0:09:02 Job 'j-24022397ddb34206bd8fa33268372626': running (progress N/A)\n",
      "0:10:03 Job 'j-24022397ddb34206bd8fa33268372626': finished (progress N/A)\n",
      "finished 3/7\n",
      "ShapefilePPWK1\n",
      "Authenticated using refresh token.\n",
      "0:00:00 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': send 'start'\n",
      "0:00:27 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': queued (progress N/A)\n",
      "0:00:33 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': queued (progress N/A)\n",
      "0:00:40 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': queued (progress N/A)\n",
      "0:00:48 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': queued (progress N/A)\n",
      "0:00:59 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': queued (progress N/A)\n",
      "0:01:11 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': queued (progress N/A)\n",
      "0:01:27 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': queued (progress N/A)\n",
      "0:01:47 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': running (progress N/A)\n",
      "0:02:13 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': running (progress N/A)\n",
      "0:02:43 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': running (progress N/A)\n",
      "0:03:21 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': running (progress N/A)\n",
      "0:04:08 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': running (progress N/A)\n",
      "0:05:07 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': running (progress N/A)\n",
      "0:06:08 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': running (progress N/A)\n",
      "0:07:08 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': running (progress N/A)\n",
      "0:08:09 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': running (progress N/A)\n",
      "0:09:10 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': running (progress N/A)\n",
      "0:10:11 Job 'j-240223aefeb04f6fa7bede5f0cff64b5': finished (progress N/A)\n",
      "finished 4/7\n"
     ]
    }
   ],
   "source": [
    "filedir = r'./extra_fields/'\n",
    "i=1\n",
    "for folder in os.listdir(filedir):\n",
    "    for file in os.listdir(os.path.join(filedir,folder)):\n",
    "        if file.endswith('.shp'):\n",
    "            #if i < 8:\n",
    "            #    i+=1\n",
    "            #    continue\n",
    "            \n",
    "            print(file.split('.')[0])\n",
    "            gdf = gpd.read_file(os.path.join(filedir,folder,file))\n",
    "            geom = json.loads(gdf.geometry.convex_hull.to_json())\n",
    "            bbox = BoundingBoxExtent(geom['bbox'][0],geom['bbox'][1],geom['bbox'][2],geom['bbox'][3])\n",
    "            bbox_simple = {\"west\": geom['bbox'][0],\n",
    "                            \"south\":geom['bbox'][1],\n",
    "                            \"east\":geom['bbox'][2],\n",
    "                            \"north\":geom['bbox'][3]}\n",
    "                \n",
    "            output_path = os.path.join(filedir,'output',file.split('.')[0]+'.csv')\n",
    "            s2_dc = extract_and_save_simple(b_simple,t_simple,bbox_simple,geom)\n",
    "            create_job(s2_dc,output_path)\n",
    "            print(f'finished {i}/{len(os.listdir(filedir))}')\n",
    "\n",
    "            i+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r'./extra_fields/output'\n",
    "for csv in os.listdir(output_dir):\n",
    "    csv_open = gpd.read_file(os.path.join(output_dir,csv))\n",
    "    new_name = csv.split('file')[-1]\n",
    "\n",
    "    in_cols = [col for col in csv_open.columns  if 'avg' in col]\n",
    "    out_cols = ['B'+str(int(col.split(')')[0].split('_')[-1])+1)+'_mean' for col in in_cols]\n",
    "    csv_open = csv_open[['date']+in_cols]\n",
    "    csv_open = csv_open.rename(columns=dict(zip(in_cols,out_cols)))\n",
    "    csv_open = csv_open.sort_values(by=['date']).reset_index(drop=True)\n",
    "    \n",
    "    csv_open.to_csv(os.path.join(output_dir,new_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VI_dry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
